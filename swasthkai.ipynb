{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neHDWclgp8TB",
        "outputId": "622fd7ef-9254-4a60-a140-a461786fba84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'yolov5' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcqalwwFxLHw",
        "outputId": "5266f375-5a18-401f-e0d4-ac20e95cc74a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/yolov5\n"
          ]
        }
      ],
      "source": [
        "cd yolov5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDMyfy5AxM3m",
        "outputId": "5d4d9d30-2e43-4f11-c9ce-87c1f7573a36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (3.1.41)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.8.0.76)\n",
            "Requirement already satisfied: Pillow>=9.4.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (9.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.11.4)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.16.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (4.66.1)\n",
            "Requirement already satisfied: ultralytics>=8.0.232 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (8.1.11)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (0.13.1)\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (67.7.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.48.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2.1.0)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.0.232->-r requirements.txt (line 18)) (9.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2023.4)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dY0rB__GxQNM",
        "outputId": "efe7dc34-5348-4a81-d3ba-a0d3e201719b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.9.0.80)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.23.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python-headless"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxLcvDuixSuZ",
        "outputId": "c93183e0-338d-430b-9397-9e04f90ba3ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/yolov5/data\n"
          ]
        }
      ],
      "source": [
        "cd data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVHwCLkWxUxW",
        "outputId": "e14f9d60-1afa-4e2d-96ff-fe53066ba41e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/dataset.zip\n",
            "replace dataset/train/images/1_png.rf.2ce451dc4ca32c74e58a901345dae5ae.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip /content/dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VENnnwb0dUow"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvMK_-zjzCw8",
        "outputId": "73469966-a25f-42e6-cab1-d7d763e7050d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YxeG1yS0Yea",
        "outputId": "25c36cd8-9ea6-4f44-ce57-0e800261eee8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'data'\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "cd data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dr3Te_M50VPE",
        "outputId": "985be46c-c2e1-4777-c418-db5dc149ecc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-02-10 13:42:26.561712: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-10 13:42:26.561778: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-10 13:42:26.563298: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=150, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-284-g95ebf68f Python-3.10.12 torch-2.1.0+cu121 CPU\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 109MB/s]\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 237MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7027720 parameters, 7027720 gradients, 16.0 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/data/dataset/train/labels... 102 images, 0 backgrounds, 0 corrupt: 100% 102/102 [00:00<00:00, 531.62it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolov5/data/dataset/train/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/data/dataset/valid/labels... 9 images, 0 backgrounds, 0 corrupt: 100% 9/9 [00:00<00:00, 130.17it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolov5/data/dataset/valid/labels.cache\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.33 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/exp2/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp2\u001b[0m\n",
            "Starting training for 150 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      0/149         0G     0.1145    0.03666    0.04106         20        640: 100% 7/7 [02:34<00:00, 22.11s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/1 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 0.950s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:05<00:00,  5.03s/it]\n",
            "                   all          9         24          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      1/149         0G     0.1073    0.03488    0.04032         25        640: 100% 7/7 [02:15<00:00, 19.33s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/1 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 0.950s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:04<00:00,  4.42s/it]\n",
            "                   all          9         24   0.000543      0.037   0.000363   0.000145\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      2/149         0G     0.0977    0.03835    0.03896         37        640: 100% 7/7 [02:26<00:00, 20.89s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/1 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 0.950s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:04<00:00,  4.78s/it]\n",
            "                   all          9         24    0.00146      0.159    0.00185   0.000331\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      3/149         0G    0.08802    0.03403     0.0351         10        640: 100% 7/7 [02:23<00:00, 20.47s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:05<00:00,  5.40s/it]\n",
            "                   all          9         24     0.0024      0.274     0.0404     0.0063\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      4/149         0G    0.08932    0.03904    0.03584         25        640: 100% 7/7 [02:28<00:00, 21.20s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:04<00:00,  4.34s/it]\n",
            "                   all          9         24    0.00291      0.343     0.0147    0.00382\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      5/149         0G    0.08592    0.03784    0.03434         18        640: 100% 7/7 [02:24<00:00, 20.62s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:04<00:00,  4.30s/it]\n",
            "                   all          9         24    0.00404      0.505     0.0721     0.0345\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      6/149         0G    0.07864     0.0388    0.03107         25        640: 100% 7/7 [02:29<00:00, 21.43s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:05<00:00,  5.33s/it]\n",
            "                   all          9         24      0.865     0.0741      0.113     0.0456\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      7/149         0G    0.07338    0.03799    0.02836         37        640: 100% 7/7 [02:32<00:00, 21.82s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:05<00:00,  5.34s/it]\n",
            "                   all          9         24      0.868      0.113      0.147     0.0309\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      8/149         0G    0.07459      0.034    0.02666         29        640: 100% 7/7 [02:30<00:00, 21.53s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:04<00:00,  4.33s/it]\n",
            "                   all          9         24      0.734      0.148     0.0487    0.00828\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      9/149         0G    0.07395    0.03423    0.02463         16        640: 100% 7/7 [02:28<00:00, 21.22s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:05<00:00,  5.09s/it]\n",
            "                   all          9         24      0.809      0.185      0.146     0.0351\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     10/149         0G    0.07202    0.03653     0.0226         27        640: 100% 7/7 [02:32<00:00, 21.78s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:05<00:00,  5.05s/it]\n",
            "                   all          9         24      0.848      0.185      0.203       0.12\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     11/149         0G    0.06969    0.03108    0.02127         22        640: 100% 7/7 [02:28<00:00, 21.26s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:04<00:00,  4.34s/it]\n",
            "                   all          9         24      0.809      0.185      0.137     0.0774\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     12/149         0G    0.06747    0.03407    0.01986         35        640: 100% 7/7 [02:28<00:00, 21.23s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:04<00:00,  4.74s/it]\n",
            "                   all          9         24      0.765      0.217      0.108     0.0282\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     13/149         0G    0.06732    0.03509    0.01718         33        640: 100% 7/7 [02:27<00:00, 21.11s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:04<00:00,  4.12s/it]\n",
            "                   all          9         24      0.472      0.347       0.19     0.0367\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     14/149         0G    0.07089     0.0311    0.01578         29        640: 100% 7/7 [02:29<00:00, 21.42s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:04<00:00,  4.03s/it]\n",
            "                   all          9         24      0.884      0.222      0.234     0.0849\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     15/149         0G    0.07142    0.02864    0.01573         14        640: 100% 7/7 [02:38<00:00, 22.64s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:04<00:00,  4.09s/it]\n",
            "                   all          9         24      0.478      0.384      0.237     0.0657\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     16/149         0G    0.06805    0.03014      0.015         32        640: 100% 7/7 [02:31<00:00, 21.64s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:04<00:00,  4.28s/it]\n",
            "                   all          9         24      0.463       0.31       0.19     0.0516\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     17/149         0G    0.06564    0.03056    0.01476         30        640: 100% 7/7 [02:28<00:00, 21.22s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:03<00:00,  3.82s/it]\n",
            "                   all          9         24      0.469      0.227      0.157     0.0504\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     18/149         0G    0.06461    0.02952    0.01327         24        640: 100% 7/7 [02:30<00:00, 21.44s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:03<00:00,  3.90s/it]\n",
            "                   all          9         24      0.448      0.264      0.132     0.0351\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     19/149         0G    0.06342    0.03075    0.01158         26        640: 100% 7/7 [02:32<00:00, 21.78s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:04<00:00,  4.14s/it]\n",
            "                   all          9         24      0.462      0.472      0.261      0.097\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     20/149         0G    0.06278    0.02602   0.009658         23        640: 100% 7/7 [02:29<00:00, 21.41s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:04<00:00,  4.04s/it]\n",
            "                   all          9         24      0.595      0.269      0.151     0.0823\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     21/149         0G    0.05736    0.02987   0.009468         23        640: 100% 7/7 [02:26<00:00, 20.92s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:04<00:00,  4.50s/it]\n",
            "                   all          9         24       0.53      0.306      0.235     0.0865\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     22/149         0G    0.05934    0.02876   0.008723         32        640: 100% 7/7 [02:32<00:00, 21.75s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:04<00:00,  4.49s/it]\n",
            "                   all          9         24      0.563      0.343      0.299      0.131\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     23/149         0G    0.05457    0.02548    0.01006         20        640: 100% 7/7 [02:35<00:00, 22.16s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:03<00:00,  3.81s/it]\n",
            "                   all          9         24      0.592      0.306      0.307      0.135\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     24/149         0G    0.05594    0.02312   0.008781         20        640: 100% 7/7 [02:28<00:00, 21.17s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:03<00:00,  3.86s/it]\n",
            "                   all          9         24      0.601      0.343      0.373      0.192\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     25/149         0G     0.0549    0.02772   0.007586         24        640: 100% 7/7 [02:27<00:00, 21.05s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:03<00:00,  3.99s/it]\n",
            "                   all          9         24      0.493      0.463       0.31       0.13\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     26/149         0G    0.05139    0.02642   0.007546         23        640: 100% 7/7 [02:32<00:00, 21.86s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:03<00:00,  4.00s/it]\n",
            "                   all          9         24      0.588      0.426      0.357      0.171\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     27/149         0G    0.05647    0.02345   0.006554         30        640: 100% 7/7 [02:32<00:00, 21.76s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:03<00:00,  3.77s/it]\n",
            "                   all          9         24      0.892      0.347      0.443      0.196\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     28/149         0G    0.05572     0.0234   0.006182         20        640: 100% 7/7 [02:29<00:00, 21.35s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:03<00:00,  3.86s/it]\n",
            "                   all          9         24      0.802      0.426      0.484       0.25\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     29/149         0G    0.05173     0.0207   0.005614         30        640: 100% 7/7 [02:24<00:00, 20.65s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:04<00:00,  4.73s/it]\n",
            "                   all          9         24      0.657      0.399      0.446       0.24\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     30/149         0G    0.05384    0.02541   0.006082         17        640: 100% 7/7 [02:36<00:00, 22.40s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:04<00:00,  4.11s/it]\n",
            "                   all          9         24      0.706      0.422      0.417      0.172\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     31/149         0G    0.04989    0.02061   0.006127         13        640: 100% 7/7 [02:26<00:00, 20.87s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:04<00:00,  4.37s/it]\n",
            "                   all          9         24       0.69      0.394      0.476      0.197\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     32/149         0G    0.05388    0.02127    0.00454         25        640: 100% 7/7 [02:34<00:00, 22.03s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:04<00:00,  4.50s/it]\n",
            "                   all          9         24      0.787      0.426      0.525      0.277\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     33/149         0G    0.04907    0.02176   0.005723         28        640: 100% 7/7 [02:25<00:00, 20.82s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/1 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "!python train.py --img 640 --batch 16 --epochs 150 --save-period 1 --data /content/data.yaml --weights 'yolov5s.pt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jC3t9YHU5xly",
        "outputId": "745f3bf7-2438-43e6-99ab-812926d737cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open /content/yolov5/data/test-data.zip, /content/yolov5/data/test-data.zip.zip or /content/yolov5/data/test-data.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "y!unzip /content/yolov5/data/test-data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fbheualk6LN-",
        "outputId": "a3f5f8a2-ebcb-4092-841d-c40fd81513cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/content/yolov5/data/test-data'\n",
            "/content/yolov5/data\n"
          ]
        }
      ],
      "source": [
        "cd /content/yolov5/data/test-data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAXD5JfUNMb_",
        "outputId": "d6481626-2fc0-463b-ec5c-3c54629af2f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/yolov5/runs/train/exp/weights/best.pt'], source=/content/yolov5/data/test-data, data=../data/coco128.yaml, imgsz=[640, 640], conf_thres=0.4, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_csv=False, save_conf=True, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 v7.0-284-g95ebf68f Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov5/detect.py\", line 309, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/yolov5/detect.py\", line 304, in main\n",
            "    run(**vars(opt))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/yolov5/detect.py\", line 115, in run\n",
            "    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)\n",
            "  File \"/content/yolov5/models/common.py\", line 370, in __init__\n",
            "    model = attempt_load(weights if isinstance(weights, list) else w, device=device, inplace=True, fuse=fuse)\n",
            "  File \"/content/yolov5/models/experimental.py\", line 78, in attempt_load\n",
            "    ckpt = torch.load(attempt_download(w), map_location=\"cpu\")  # load\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 986, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 435, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 416, in __init__\n",
            "    super().__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/yolov5/runs/train/exp/weights/best.pt'\n"
          ]
        }
      ],
      "source": [
        "!python /content/yolov5/detect.py --source /content/yolov5/data/test-data --weights /content/yolov5/runs/train/exp/weights/best.pt --conf 0.4 --save-txt --save-conf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNfticcw7MNc"
      },
      "outputs": [],
      "source": [
        "# !pip install pytesseract\n",
        "# !sudo apt install tesseract-ocr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27ZCOEGnm38x"
      },
      "outputs": [],
      "source": [
        "# import cv2\n",
        "# import pytesseract\n",
        "# from google.colab.patches import cv2_imshow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "Ev_Yj233rbVr",
        "outputId": "02142d9e-800d-4eeb-e3c1-79738bb9e03d"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/yolov5/runs/detect/exp/images'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-bbc516bd3613>\u001b[0m in \u001b[0;36m<cell line: 52>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mlabels_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/yolov5/runs/detect/exp/labels'\u001b[0m  \u001b[0;31m# Directory containing labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0moutput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/yolov5/data/cropped'\u001b[0m  \u001b[0;31m# Directory to save cropped images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mcrop_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-bbc516bd3613>\u001b[0m in \u001b[0;36mcrop_images\u001b[0;34m(images_dir, labels_dir, output_dir)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcrop_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Iterate through each image file in the images directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimage_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimage_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mimage_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mimage_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/yolov5/runs/detect/exp/images'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "def crop_images(images_dir, labels_dir, output_dir):\n",
        "    # Iterate through each image file in the images directory\n",
        "    for image_file in os.listdir(images_dir):\n",
        "        if image_file.endswith('.png') or image_file.endswith('.jpg'):\n",
        "            image_name = os.path.splitext(image_file)[0]\n",
        "            image_path = os.path.join(images_dir, image_file)\n",
        "            label_file = os.path.join(labels_dir, image_name + '.txt')\n",
        "            if os.path.exists(label_file):\n",
        "                crop_image(image_path, label_file, output_dir, image_name)\n",
        "\n",
        "def crop_image(image_path, labels_path, output_dir, image_name):\n",
        "    # Load image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Read bounding box coordinates from text file\n",
        "    with open(labels_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    # Create directory to save cropped images if it doesn't exist\n",
        "    output_image_dir = os.path.join(output_dir, image_name)\n",
        "    os.makedirs(output_image_dir, exist_ok=True)\n",
        "\n",
        "    # Process each line in the text file\n",
        "    for line in lines:\n",
        "        parts = line.split()\n",
        "        class_id = int(parts[0])\n",
        "        x_center = float(parts[1])\n",
        "        y_center = float(parts[2])\n",
        "        width = float(parts[3])\n",
        "        height = float(parts[4])\n",
        "\n",
        "        # Convert relative coordinates to absolute coordinates\n",
        "        x1 = int((x_center - width/2) * image.shape[1])\n",
        "        y1 = int((y_center - height/2) * image.shape[0])\n",
        "        x2 = int((x_center + width/2) * image.shape[1])\n",
        "        y2 = int((y_center + height/2) * image.shape[0])\n",
        "\n",
        "        # Crop the region of interest\n",
        "        cropped_image = image[y1:y2, x1:x2]\n",
        "\n",
        "        # Save the cropped image\n",
        "        output_file = os.path.join(output_image_dir, f'cropped_image_class_{class_id}_{image_name}.jpg')\n",
        "        cv2.imwrite(output_file, cropped_image)\n",
        "\n",
        "# Example usage:\n",
        "images_dir = '/content/yolov5/runs/detect/exp/images'  # Directory containing images\n",
        "labels_dir = '/content/yolov5/runs/detect/exp/labels'  # Directory containing labels\n",
        "output_dir = '/content/yolov5/data/cropped'  # Directory to save cropped images\n",
        "crop_images(images_dir, labels_dir, output_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BESZ-MpR_X5z"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def enhance_images(input_dir, output_dir):\n",
        "    # Iterate through each directory containing cropped images\n",
        "    for root, dirs, files in os.walk(input_dir):\n",
        "        for dir_name in dirs:\n",
        "            input_image_dir = os.path.join(input_dir, dir_name)\n",
        "            output_image_dir = os.path.join(output_dir, dir_name)\n",
        "            os.makedirs(output_image_dir, exist_ok=True)\n",
        "\n",
        "            # Iterate through each image file in the input directory\n",
        "            for image_file in os.listdir(input_image_dir):\n",
        "                if image_file.endswith('.jpg') or image_file.endswith('.png'):\n",
        "                    input_image_path = os.path.join(input_image_dir, image_file)\n",
        "\n",
        "                    # Load image\n",
        "                    image = cv2.imread(input_image_path)\n",
        "\n",
        "                    # Enhance image\n",
        "                    enhanced_image = enhance_image(image)\n",
        "\n",
        "                    # Save enhanced image\n",
        "                    output_image_path = os.path.join(output_image_dir, image_file)\n",
        "                    cv2.imwrite(output_image_path, enhanced_image)\n",
        "\n",
        "def enhance_image(image):\n",
        "    # Increase contrast\n",
        "    alpha = 1.5  # Contrast control (1.0-3.0)\n",
        "    beta = 0    # Brightness control (0-100)\n",
        "    contrast_enhanced = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
        "\n",
        "    # Sharpening\n",
        "    sharpened = cv2.filter2D(contrast_enhanced, -1, kernel=np.array(sharpening_kernel))\n",
        "\n",
        "    return sharpened\n",
        "\n",
        "# Define sharpening kernel\n",
        "sharpening_kernel = np.array([[-1, -1, -1],\n",
        "                               [-1, 9, -1],\n",
        "                               [-1, -1, -1]])\n",
        "\n",
        "# Example usage:\n",
        "input_dir = '/content/yolov5/data/cropped'  # Directory containing cropped images\n",
        "output_dir = '/content/yolov5/data/enhanced'  # Directory to save enhanced images\n",
        "enhance_images(input_dir, output_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xnu9Z199QpYe"
      },
      "source": [
        "### Till this we have cropped and enhanced the bounding boxes for the better OCR."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpcpM4US-D-q"
      },
      "outputs": [],
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCVB9XfbANDZ"
      },
      "outputs": [],
      "source": [
        "import pytesseract\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HmP4ouwCHJs"
      },
      "outputs": [],
      "source": [
        "image_path = '/content/yolov5/data/enhanced/real2/cropped_image_class_0_real2.jpg'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wm_SqwpyCMgi"
      },
      "outputs": [],
      "source": [
        "image = Image.open(image_path)\n",
        "\n",
        "# Use pytesseract to extract text\n",
        "extracted_text = pytesseract.image_to_string(image)\n",
        "\n",
        "# Print the extracted text\n",
        "print(extracted_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgriIKzmCPgm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}